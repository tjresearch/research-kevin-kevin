{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers, layers, models\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "image_dir = \"images/lattice_points\"\n",
    "train_files = [[], []]\n",
    "\n",
    "for file in os.listdir(os.path.join(image_dir, \"no\")):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        train_files[0].append(os.path.join(image_dir, \"no\", file))\n",
    "\n",
    "for file in os.listdir(os.path.join(image_dir, \"yes\")):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        train_files[1].append(os.path.join(image_dir, \"yes\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(2):\n",
    "    for file in train_files[i]:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "        img = cv2.Canny(img, 0, 255)\n",
    "        \n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        all_images.append(img)\n",
    "        \n",
    "        label = [0, 0]\n",
    "        label[i] = 1\n",
    "        all_labels.append(label)\n",
    "\n",
    "all_images = np.array(all_images)[..., np.newaxis]\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5366, 21, 21, 1) (5366, 2)\n",
      "1.0\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_images.shape, all_labels.shape)\n",
    "print(all_images.max())\n",
    "print(all_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(all_images[-1][:, :, 0], cmap=\"gray\")\n",
    "print(all_labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "\n",
    "train_indices = random.sample(range(len(all_images)), int(len(all_images) * 0.8))\n",
    "\n",
    "for i in range(len(all_images)):\n",
    "    if i in train_indices:\n",
    "        train_images.append(all_images[i])\n",
    "        train_labels.append(all_labels[i])\n",
    "    else:\n",
    "        valid_images.append(all_images[i])\n",
    "        valid_labels.append(all_labels[i])\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "valid_images = np.array(valid_images)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=4,\n",
    "    height_shift_range=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(441, input_shape=(21, 21, 1)))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in [3, 2, 1]:\n",
    "        model.add(layers.Conv2D(16, j, activation=\"elu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "model.add(layers.Dense(128, activation=\"elu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "model.compile(optimizers.RMSprop(lr=1e-3), loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 21, 21, 441)       882       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 19, 19, 16)        63520     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 18, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 16)        272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 9, 16)          64        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 16)          1040      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3, 3, 16)          64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3, 3, 128)         2176      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2306      \n",
      "=================================================================\n",
      "Total params: 73,956\n",
      "Trainable params: 73,892\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(train_images, train_labels, batch_size):\n",
    "    gen = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "    while True:\n",
    "        x, y = gen.next()\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0327 14:17:01.142286 4537986496 deprecation.py:323] From <ipython-input-13-a4605e9f4332>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "W0327 14:17:01.161406 4537986496 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 85 steps, validate on 1074 samples\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 14s 168ms/step - loss: 0.4419 - categorical_accuracy: 0.7849 - val_loss: 0.4411 - val_categorical_accuracy: 0.8901\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 14s 160ms/step - loss: 0.3129 - categorical_accuracy: 0.8659 - val_loss: 0.2574 - val_categorical_accuracy: 0.9534\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.2501 - categorical_accuracy: 0.8977 - val_loss: 0.1211 - val_categorical_accuracy: 0.9646\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.2063 - categorical_accuracy: 0.9229 - val_loss: 0.0775 - val_categorical_accuracy: 0.9767\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.1770 - categorical_accuracy: 0.9347 - val_loss: 0.0670 - val_categorical_accuracy: 0.9823\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.1685 - categorical_accuracy: 0.9415 - val_loss: 0.1063 - val_categorical_accuracy: 0.9702\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.1546 - categorical_accuracy: 0.9463 - val_loss: 0.0884 - val_categorical_accuracy: 0.9777\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 13s 149ms/step - loss: 0.1450 - categorical_accuracy: 0.9479 - val_loss: 0.0941 - val_categorical_accuracy: 0.9665\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 13s 149ms/step - loss: 0.1474 - categorical_accuracy: 0.9496 - val_loss: 0.0750 - val_categorical_accuracy: 0.9823\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 13s 149ms/step - loss: 0.1505 - categorical_accuracy: 0.9470 - val_loss: 0.8267 - val_categorical_accuracy: 0.7142\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 13s 149ms/step - loss: 0.1319 - categorical_accuracy: 0.9526 - val_loss: 0.0739 - val_categorical_accuracy: 0.9777\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 13s 148ms/step - loss: 0.1473 - categorical_accuracy: 0.9526 - val_loss: 0.0639 - val_categorical_accuracy: 0.9842\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 13s 149ms/step - loss: 0.1304 - categorical_accuracy: 0.9540 - val_loss: 0.0673 - val_categorical_accuracy: 0.9804\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1430 - categorical_accuracy: 0.9538 - val_loss: 0.1061 - val_categorical_accuracy: 0.9693\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 13s 157ms/step - loss: 0.1219 - categorical_accuracy: 0.9559 - val_loss: 0.0615 - val_categorical_accuracy: 0.9842\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 13s 155ms/step - loss: 0.1340 - categorical_accuracy: 0.9571 - val_loss: 0.0758 - val_categorical_accuracy: 0.9767\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.1214 - categorical_accuracy: 0.9569 - val_loss: 0.0701 - val_categorical_accuracy: 0.9758\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1256 - categorical_accuracy: 0.9592 - val_loss: 0.1086 - val_categorical_accuracy: 0.9693\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.1075 - categorical_accuracy: 0.9642 - val_loss: 0.0645 - val_categorical_accuracy: 0.9795\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 13s 157ms/step - loss: 0.1220 - categorical_accuracy: 0.9606 - val_loss: 0.1902 - val_categorical_accuracy: 0.9246\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1165 - categorical_accuracy: 0.9632 - val_loss: 0.1573 - val_categorical_accuracy: 0.9525\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 13s 152ms/step - loss: 0.1254 - categorical_accuracy: 0.9628 - val_loss: 0.0731 - val_categorical_accuracy: 0.9814\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1171 - categorical_accuracy: 0.9620 - val_loss: 0.0783 - val_categorical_accuracy: 0.9702\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1092 - categorical_accuracy: 0.9651 - val_loss: 0.0805 - val_categorical_accuracy: 0.9786\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1068 - categorical_accuracy: 0.9670 - val_loss: 0.4013 - val_categorical_accuracy: 0.8101\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 13s 152ms/step - loss: 0.1036 - categorical_accuracy: 0.9656 - val_loss: 0.0888 - val_categorical_accuracy: 0.9721\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1105 - categorical_accuracy: 0.9686 - val_loss: 0.1051 - val_categorical_accuracy: 0.9637\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0951 - categorical_accuracy: 0.9701 - val_loss: 0.1377 - val_categorical_accuracy: 0.9525\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1116 - categorical_accuracy: 0.9656 - val_loss: 0.1563 - val_categorical_accuracy: 0.9395\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1046 - categorical_accuracy: 0.9682 - val_loss: 0.2314 - val_categorical_accuracy: 0.9134\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.0986 - categorical_accuracy: 0.9691 - val_loss: 0.0680 - val_categorical_accuracy: 0.9842\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.1078 - categorical_accuracy: 0.9672 - val_loss: 0.0771 - val_categorical_accuracy: 0.9777\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0945 - categorical_accuracy: 0.9691 - val_loss: 0.0713 - val_categorical_accuracy: 0.9749\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.1173 - categorical_accuracy: 0.9665 - val_loss: 0.0838 - val_categorical_accuracy: 0.9795\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.0923 - categorical_accuracy: 0.9694 - val_loss: 0.0758 - val_categorical_accuracy: 0.9832\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.0936 - categorical_accuracy: 0.9698 - val_loss: 0.2883 - val_categorical_accuracy: 0.8985\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 13s 154ms/step - loss: 0.0975 - categorical_accuracy: 0.9701 - val_loss: 0.0556 - val_categorical_accuracy: 0.9879\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 14s 160ms/step - loss: 0.1021 - categorical_accuracy: 0.9712 - val_loss: 0.1089 - val_categorical_accuracy: 0.9674\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.1110 - categorical_accuracy: 0.9672 - val_loss: 0.1058 - val_categorical_accuracy: 0.9665\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 13s 152ms/step - loss: 0.1009 - categorical_accuracy: 0.9677 - val_loss: 0.5640 - val_categorical_accuracy: 0.6480\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 13s 154ms/step - loss: 0.0965 - categorical_accuracy: 0.9722 - val_loss: 0.0608 - val_categorical_accuracy: 0.9814\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.0933 - categorical_accuracy: 0.9719 - val_loss: 0.0721 - val_categorical_accuracy: 0.9804\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0888 - categorical_accuracy: 0.9760 - val_loss: 0.0978 - val_categorical_accuracy: 0.9674\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0940 - categorical_accuracy: 0.9743 - val_loss: 0.1192 - val_categorical_accuracy: 0.9711\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.1019 - categorical_accuracy: 0.9694 - val_loss: 0.1018 - val_categorical_accuracy: 0.9693\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0868 - categorical_accuracy: 0.9738 - val_loss: 0.0791 - val_categorical_accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.0874 - categorical_accuracy: 0.9741 - val_loss: 0.0846 - val_categorical_accuracy: 0.9758\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0879 - categorical_accuracy: 0.9776 - val_loss: 0.0610 - val_categorical_accuracy: 0.9823\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0933 - categorical_accuracy: 0.9734 - val_loss: 0.0632 - val_categorical_accuracy: 0.9842\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0971 - categorical_accuracy: 0.9715 - val_loss: 0.0625 - val_categorical_accuracy: 0.9870\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0928 - categorical_accuracy: 0.9724 - val_loss: 0.1067 - val_categorical_accuracy: 0.9730\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0945 - categorical_accuracy: 0.9743 - val_loss: 0.0732 - val_categorical_accuracy: 0.9767\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0857 - categorical_accuracy: 0.9736 - val_loss: 0.0701 - val_categorical_accuracy: 0.9823\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0889 - categorical_accuracy: 0.9741 - val_loss: 0.0614 - val_categorical_accuracy: 0.9860\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0820 - categorical_accuracy: 0.9783 - val_loss: 0.0642 - val_categorical_accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0738 - categorical_accuracy: 0.9797 - val_loss: 0.1344 - val_categorical_accuracy: 0.9562\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0907 - categorical_accuracy: 0.9727 - val_loss: 0.0804 - val_categorical_accuracy: 0.9786\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0874 - categorical_accuracy: 0.9760 - val_loss: 0.0862 - val_categorical_accuracy: 0.9739\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0864 - categorical_accuracy: 0.9757 - val_loss: 0.0594 - val_categorical_accuracy: 0.9879\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0926 - categorical_accuracy: 0.9755 - val_loss: 0.0953 - val_categorical_accuracy: 0.9749\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0996 - categorical_accuracy: 0.9731 - val_loss: 0.0617 - val_categorical_accuracy: 0.9851\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0877 - categorical_accuracy: 0.9767 - val_loss: 0.0643 - val_categorical_accuracy: 0.9860\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0996 - categorical_accuracy: 0.9734 - val_loss: 0.0609 - val_categorical_accuracy: 0.9860\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0729 - categorical_accuracy: 0.9795 - val_loss: 0.0845 - val_categorical_accuracy: 0.9814\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 15s 175ms/step - loss: 0.0871 - categorical_accuracy: 0.9741 - val_loss: 0.0534 - val_categorical_accuracy: 0.9898\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0828 - categorical_accuracy: 0.9776 - val_loss: 0.0721 - val_categorical_accuracy: 0.9823\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 14s 170ms/step - loss: 0.0857 - categorical_accuracy: 0.9743 - val_loss: 0.0745 - val_categorical_accuracy: 0.9860\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 18s 206ms/step - loss: 0.0884 - categorical_accuracy: 0.9762 - val_loss: 0.0868 - val_categorical_accuracy: 0.9749\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.0781 - categorical_accuracy: 0.9745 - val_loss: 0.0550 - val_categorical_accuracy: 0.9907\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 15s 178ms/step - loss: 0.0904 - categorical_accuracy: 0.9757 - val_loss: 0.0691 - val_categorical_accuracy: 0.9860\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 15s 172ms/step - loss: 0.0796 - categorical_accuracy: 0.9771 - val_loss: 0.0705 - val_categorical_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 15s 182ms/step - loss: 0.0710 - categorical_accuracy: 0.9809 - val_loss: 0.0661 - val_categorical_accuracy: 0.9870\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 15s 175ms/step - loss: 0.0880 - categorical_accuracy: 0.9767 - val_loss: 0.0661 - val_categorical_accuracy: 0.9860\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 14s 163ms/step - loss: 0.0754 - categorical_accuracy: 0.9790 - val_loss: 0.0593 - val_categorical_accuracy: 0.9851\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 13s 156ms/step - loss: 0.0811 - categorical_accuracy: 0.9774 - val_loss: 0.0591 - val_categorical_accuracy: 0.9870\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0905 - categorical_accuracy: 0.9764 - val_loss: 0.0661 - val_categorical_accuracy: 0.9814\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 13s 152ms/step - loss: 0.0757 - categorical_accuracy: 0.9785 - val_loss: 0.0519 - val_categorical_accuracy: 0.9870\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0858 - categorical_accuracy: 0.9736 - val_loss: 0.0582 - val_categorical_accuracy: 0.9851\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0866 - categorical_accuracy: 0.9738 - val_loss: 0.0575 - val_categorical_accuracy: 0.9888\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0791 - categorical_accuracy: 0.9767 - val_loss: 0.0648 - val_categorical_accuracy: 0.9870\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0746 - categorical_accuracy: 0.9788 - val_loss: 0.0588 - val_categorical_accuracy: 0.9870\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0837 - categorical_accuracy: 0.9793 - val_loss: 0.0628 - val_categorical_accuracy: 0.9851\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0743 - categorical_accuracy: 0.9793 - val_loss: 0.0549 - val_categorical_accuracy: 0.9898\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0748 - categorical_accuracy: 0.9804 - val_loss: 0.0573 - val_categorical_accuracy: 0.9870\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0749 - categorical_accuracy: 0.9795 - val_loss: 0.0863 - val_categorical_accuracy: 0.9749\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0880 - categorical_accuracy: 0.9762 - val_loss: 0.0796 - val_categorical_accuracy: 0.9851\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - 13s 150ms/step - loss: 0.0827 - categorical_accuracy: 0.9795 - val_loss: 0.0467 - val_categorical_accuracy: 0.9926\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - 13s 151ms/step - loss: 0.0893 - categorical_accuracy: 0.9762 - val_loss: 0.0769 - val_categorical_accuracy: 0.9777\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - 14s 165ms/step - loss: 0.0777 - categorical_accuracy: 0.9785 - val_loss: 0.0503 - val_categorical_accuracy: 0.9879\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0820 - categorical_accuracy: 0.9790 - val_loss: 0.0571 - val_categorical_accuracy: 0.9870\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - 13s 153ms/step - loss: 0.0840 - categorical_accuracy: 0.9764 - val_loss: 0.0576 - val_categorical_accuracy: 0.9870\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - 13s 155ms/step - loss: 0.0813 - categorical_accuracy: 0.9769 - val_loss: 0.0632 - val_categorical_accuracy: 0.9842\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - 13s 154ms/step - loss: 0.0802 - categorical_accuracy: 0.9783 - val_loss: 0.0597 - val_categorical_accuracy: 0.9888\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - 14s 159ms/step - loss: 0.0859 - categorical_accuracy: 0.9764 - val_loss: 0.0593 - val_categorical_accuracy: 0.9870\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - 14s 166ms/step - loss: 0.0790 - categorical_accuracy: 0.9781 - val_loss: 0.0592 - val_categorical_accuracy: 0.9870\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - 14s 165ms/step - loss: 0.0699 - categorical_accuracy: 0.9814 - val_loss: 0.0679 - val_categorical_accuracy: 0.9851\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 14s 161ms/step - loss: 0.0809 - categorical_accuracy: 0.9778 - val_loss: 0.0546 - val_categorical_accuracy: 0.9879\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - 14s 161ms/step - loss: 0.0843 - categorical_accuracy: 0.9800 - val_loss: 0.0518 - val_categorical_accuracy: 0.9860\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - 14s 162ms/step - loss: 0.0795 - categorical_accuracy: 0.9795 - val_loss: 0.0534 - val_categorical_accuracy: 0.9879\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - 14s 162ms/step - loss: 0.0864 - categorical_accuracy: 0.9785 - val_loss: 0.0570 - val_categorical_accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit_generator(generate_data(train_images, train_labels, batch_size=batch_size),\n",
    "                              steps_per_epoch=train_images.shape[0] // batch_size,\n",
    "                              epochs=epochs, validation_data = (valid_images, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lattice_points_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"lattice_points_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers, layers, models\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "image_dir = \"images/lattice_points\"\n",
    "train_files = [[], []]\n",
    "\n",
    "for file in os.listdir(os.path.join(image_dir, \"no\")):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        train_files[0].append(os.path.join(image_dir, \"no\", file))\n",
    "\n",
    "for file in os.listdir(os.path.join(image_dir, \"yes\")):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        train_files[1].append(os.path.join(image_dir, \"yes\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(2):\n",
    "    for file in train_files[i]:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "        img = cv2.Canny(img, 0, 255)\n",
    "        \n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        all_images.append(img)\n",
    "        \n",
    "        label = [0, 0]\n",
    "        label[i] = 1\n",
    "        all_labels.append(label)\n",
    "\n",
    "all_images = np.array(all_images)[..., np.newaxis]\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 21, 21, 1) (823, 2)\n",
      "1.0\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_images.shape, all_labels.shape)\n",
    "print(all_images.max())\n",
    "print(all_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x155a947b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(all_images[0][:, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "\n",
    "train_indices = random.sample(range(len(all_images)), int(len(all_images) * 0.8))\n",
    "\n",
    "for i in range(len(all_images)):\n",
    "    if i in train_indices:\n",
    "        train_images.append(all_images[i])\n",
    "        train_labels.append(all_labels[i])\n",
    "    else:\n",
    "        valid_images.append(all_images[i])\n",
    "        valid_labels.append(all_labels[i])\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "valid_images = np.array(valid_images)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=4,\n",
    "    height_shift_range=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(441, input_shape=(21, 21, 1)))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in [3, 2, 1]:\n",
    "        model.add(layers.Conv2D(16, j, activation=\"elu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "model.add(layers.Dense(128, activation=\"elu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "model.compile(optimizers.RMSprop(lr=1e-3), loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 21, 21, 441)       882       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 19, 19, 16)        63520     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 16)        272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 16)          64        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 16)          1040      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 16)          64        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3, 3, 128)         2176      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 2306      \n",
      "=================================================================\n",
      "Total params: 73,956\n",
      "Trainable params: 73,892\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(train_images, train_labels, batch_size):\n",
    "    gen = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "    while True:\n",
    "        x, y = gen.next()\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0131 20:46:28.227305 4680961472 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1.0 steps, validate on 165 samples\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2544 - categorical_accuracy: 0.8997 - val_loss: 0.5354 - val_categorical_accuracy: 0.7091\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2321 - categorical_accuracy: 0.9164 - val_loss: 0.4101 - val_categorical_accuracy: 0.7818\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2499 - categorical_accuracy: 0.9195 - val_loss: 0.5509 - val_categorical_accuracy: 0.7152\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2671 - categorical_accuracy: 0.9103 - val_loss: 0.4212 - val_categorical_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2445 - categorical_accuracy: 0.9058 - val_loss: 0.4846 - val_categorical_accuracy: 0.7273\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2287 - categorical_accuracy: 0.9103 - val_loss: 0.4695 - val_categorical_accuracy: 0.7455\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2249 - categorical_accuracy: 0.9134 - val_loss: 0.5486 - val_categorical_accuracy: 0.7212\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2507 - categorical_accuracy: 0.9103 - val_loss: 0.4500 - val_categorical_accuracy: 0.7515\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2293 - categorical_accuracy: 0.9225 - val_loss: 0.4874 - val_categorical_accuracy: 0.7333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2360 - categorical_accuracy: 0.9134 - val_loss: 0.4899 - val_categorical_accuracy: 0.7333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1922 - categorical_accuracy: 0.9422 - val_loss: 0.4072 - val_categorical_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2502 - categorical_accuracy: 0.9119 - val_loss: 0.5966 - val_categorical_accuracy: 0.7091\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2007 - categorical_accuracy: 0.9301 - val_loss: 0.4067 - val_categorical_accuracy: 0.7879\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2191 - categorical_accuracy: 0.9255 - val_loss: 0.5274 - val_categorical_accuracy: 0.7212\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2143 - categorical_accuracy: 0.9240 - val_loss: 0.4316 - val_categorical_accuracy: 0.7636\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2064 - categorical_accuracy: 0.9240 - val_loss: 0.5740 - val_categorical_accuracy: 0.7212\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2520 - categorical_accuracy: 0.9058 - val_loss: 0.4196 - val_categorical_accuracy: 0.7818\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2027 - categorical_accuracy: 0.9301 - val_loss: 0.5552 - val_categorical_accuracy: 0.7212\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2490 - categorical_accuracy: 0.9149 - val_loss: 0.5568 - val_categorical_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2239 - categorical_accuracy: 0.9179 - val_loss: 0.3275 - val_categorical_accuracy: 0.8606\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2588 - categorical_accuracy: 0.8997 - val_loss: 0.5740 - val_categorical_accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2351 - categorical_accuracy: 0.9301 - val_loss: 0.3202 - val_categorical_accuracy: 0.8424\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2569 - categorical_accuracy: 0.9088 - val_loss: 0.4415 - val_categorical_accuracy: 0.7515\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2177 - categorical_accuracy: 0.9286 - val_loss: 0.3735 - val_categorical_accuracy: 0.8061\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2361 - categorical_accuracy: 0.9195 - val_loss: 0.5215 - val_categorical_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2075 - categorical_accuracy: 0.9255 - val_loss: 0.3319 - val_categorical_accuracy: 0.8424\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2598 - categorical_accuracy: 0.9058 - val_loss: 0.5416 - val_categorical_accuracy: 0.7212\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2490 - categorical_accuracy: 0.9073 - val_loss: 0.2908 - val_categorical_accuracy: 0.9030\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2539 - categorical_accuracy: 0.9210 - val_loss: 0.5098 - val_categorical_accuracy: 0.7333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2053 - categorical_accuracy: 0.9347 - val_loss: 0.4672 - val_categorical_accuracy: 0.7273\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2039 - categorical_accuracy: 0.9255 - val_loss: 0.3698 - val_categorical_accuracy: 0.7939\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2484 - categorical_accuracy: 0.9103 - val_loss: 0.3132 - val_categorical_accuracy: 0.8727\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2281 - categorical_accuracy: 0.9210 - val_loss: 0.4939 - val_categorical_accuracy: 0.7333\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2195 - categorical_accuracy: 0.9195 - val_loss: 0.3511 - val_categorical_accuracy: 0.8242\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2356 - categorical_accuracy: 0.9195 - val_loss: 0.4322 - val_categorical_accuracy: 0.7636\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2190 - categorical_accuracy: 0.9271 - val_loss: 0.3333 - val_categorical_accuracy: 0.8606\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2102 - categorical_accuracy: 0.9286 - val_loss: 0.3649 - val_categorical_accuracy: 0.8121\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2321 - categorical_accuracy: 0.9134 - val_loss: 0.4006 - val_categorical_accuracy: 0.7636\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2239 - categorical_accuracy: 0.9255 - val_loss: 0.3705 - val_categorical_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2463 - categorical_accuracy: 0.9210 - val_loss: 0.4487 - val_categorical_accuracy: 0.7818\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2157 - categorical_accuracy: 0.9271 - val_loss: 0.2737 - val_categorical_accuracy: 0.8909\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2045 - categorical_accuracy: 0.9271 - val_loss: 0.3745 - val_categorical_accuracy: 0.8121\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2242 - categorical_accuracy: 0.9271 - val_loss: 0.3083 - val_categorical_accuracy: 0.8970\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2488 - categorical_accuracy: 0.9134 - val_loss: 0.4231 - val_categorical_accuracy: 0.7939\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1884 - categorical_accuracy: 0.9271 - val_loss: 0.3382 - val_categorical_accuracy: 0.8424\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1940 - categorical_accuracy: 0.9210 - val_loss: 0.3448 - val_categorical_accuracy: 0.8485\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2059 - categorical_accuracy: 0.9286 - val_loss: 0.3576 - val_categorical_accuracy: 0.8303\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2236 - categorical_accuracy: 0.9301 - val_loss: 0.3902 - val_categorical_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2077 - categorical_accuracy: 0.9362 - val_loss: 0.3321 - val_categorical_accuracy: 0.8606\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2070 - categorical_accuracy: 0.9225 - val_loss: 0.4468 - val_categorical_accuracy: 0.7576\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.2090 - categorical_accuracy: 0.9286 - val_loss: 0.3079 - val_categorical_accuracy: 0.8727\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2246 - categorical_accuracy: 0.9255 - val_loss: 0.4310 - val_categorical_accuracy: 0.7515\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2267 - categorical_accuracy: 0.9149 - val_loss: 0.3590 - val_categorical_accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2172 - categorical_accuracy: 0.9286 - val_loss: 0.4943 - val_categorical_accuracy: 0.7333\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2096 - categorical_accuracy: 0.9286 - val_loss: 0.4014 - val_categorical_accuracy: 0.7636\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2317 - categorical_accuracy: 0.9286 - val_loss: 0.3910 - val_categorical_accuracy: 0.7697\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2173 - categorical_accuracy: 0.9255 - val_loss: 0.5295 - val_categorical_accuracy: 0.7394\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1921 - categorical_accuracy: 0.9468 - val_loss: 0.3370 - val_categorical_accuracy: 0.8485\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1780 - categorical_accuracy: 0.9316 - val_loss: 0.4105 - val_categorical_accuracy: 0.7758\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2299 - categorical_accuracy: 0.9149 - val_loss: 0.6387 - val_categorical_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2233 - categorical_accuracy: 0.9286 - val_loss: 0.2637 - val_categorical_accuracy: 0.8970\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2090 - categorical_accuracy: 0.9225 - val_loss: 0.4806 - val_categorical_accuracy: 0.7455\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2113 - categorical_accuracy: 0.9179 - val_loss: 0.3429 - val_categorical_accuracy: 0.8727\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2239 - categorical_accuracy: 0.9255 - val_loss: 0.3715 - val_categorical_accuracy: 0.8424\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2049 - categorical_accuracy: 0.9240 - val_loss: 0.3402 - val_categorical_accuracy: 0.8545\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2221 - categorical_accuracy: 0.9225 - val_loss: 0.3339 - val_categorical_accuracy: 0.8485\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2020 - categorical_accuracy: 0.9225 - val_loss: 0.2834 - val_categorical_accuracy: 0.8970\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2088 - categorical_accuracy: 0.9210 - val_loss: 0.4048 - val_categorical_accuracy: 0.7939\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2168 - categorical_accuracy: 0.9210 - val_loss: 0.2924 - val_categorical_accuracy: 0.8848\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2067 - categorical_accuracy: 0.9149 - val_loss: 0.3390 - val_categorical_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2482 - categorical_accuracy: 0.9058 - val_loss: 0.4285 - val_categorical_accuracy: 0.7818\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2113 - categorical_accuracy: 0.9210 - val_loss: 0.3087 - val_categorical_accuracy: 0.8788\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2247 - categorical_accuracy: 0.9058 - val_loss: 0.2906 - val_categorical_accuracy: 0.8909\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2369 - categorical_accuracy: 0.9271 - val_loss: 0.2089 - val_categorical_accuracy: 0.9091\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2158 - categorical_accuracy: 0.9134 - val_loss: 0.2559 - val_categorical_accuracy: 0.9212\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2010 - categorical_accuracy: 0.9407 - val_loss: 0.2501 - val_categorical_accuracy: 0.9212\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2084 - categorical_accuracy: 0.9286 - val_loss: 0.2342 - val_categorical_accuracy: 0.9212\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2078 - categorical_accuracy: 0.9286 - val_loss: 0.3567 - val_categorical_accuracy: 0.8545\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1922 - categorical_accuracy: 0.9255 - val_loss: 0.2408 - val_categorical_accuracy: 0.9091\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2141 - categorical_accuracy: 0.9347 - val_loss: 0.2329 - val_categorical_accuracy: 0.9152\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2364 - categorical_accuracy: 0.9103 - val_loss: 0.3403 - val_categorical_accuracy: 0.8424\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2109 - categorical_accuracy: 0.9240 - val_loss: 0.2131 - val_categorical_accuracy: 0.9152\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2051 - categorical_accuracy: 0.9286 - val_loss: 0.2464 - val_categorical_accuracy: 0.9212\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2317 - categorical_accuracy: 0.9210 - val_loss: 0.2764 - val_categorical_accuracy: 0.9091\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1969 - categorical_accuracy: 0.9347 - val_loss: 0.2281 - val_categorical_accuracy: 0.9212\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1730 - categorical_accuracy: 0.9377 - val_loss: 0.2781 - val_categorical_accuracy: 0.9030\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1886 - categorical_accuracy: 0.9362 - val_loss: 0.2251 - val_categorical_accuracy: 0.9152\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2185 - categorical_accuracy: 0.9210 - val_loss: 0.2449 - val_categorical_accuracy: 0.9091\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2095 - categorical_accuracy: 0.9392 - val_loss: 0.2659 - val_categorical_accuracy: 0.9091\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2241 - categorical_accuracy: 0.9331 - val_loss: 0.2738 - val_categorical_accuracy: 0.9030\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2067 - categorical_accuracy: 0.9331 - val_loss: 0.2683 - val_categorical_accuracy: 0.9091\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2086 - categorical_accuracy: 0.9301 - val_loss: 0.2101 - val_categorical_accuracy: 0.9152\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1886 - categorical_accuracy: 0.9392 - val_loss: 0.1918 - val_categorical_accuracy: 0.9273\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2049 - categorical_accuracy: 0.9347 - val_loss: 0.2989 - val_categorical_accuracy: 0.9030\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1984 - categorical_accuracy: 0.9316 - val_loss: 0.2036 - val_categorical_accuracy: 0.9212\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2002 - categorical_accuracy: 0.9255 - val_loss: 0.2867 - val_categorical_accuracy: 0.8970\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2061 - categorical_accuracy: 0.9286 - val_loss: 0.2712 - val_categorical_accuracy: 0.8970\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2028 - categorical_accuracy: 0.9438 - val_loss: 0.1970 - val_categorical_accuracy: 0.9273\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1908 - categorical_accuracy: 0.9240 - val_loss: 0.2064 - val_categorical_accuracy: 0.9273\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2242 - categorical_accuracy: 0.9225 - val_loss: 0.2277 - val_categorical_accuracy: 0.9152\n"
     ]
    }
   ],
   "source": [
    "batch_size = train_images.shape[0]\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit_generator(generate_data(train_images, train_labels, batch_size=batch_size),\n",
    "                              steps_per_epoch=train_images.shape[0] / batch_size,\n",
    "                              epochs=epochs, validation_data = (valid_images, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lattice_points_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"lattice_points_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

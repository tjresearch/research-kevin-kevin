{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers, layers, models\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "image_dir = \"images/lattice_points\"\n",
    "train_files = [[], []]\n",
    "\n",
    "for file in os.listdir(os.path.join(image_dir, \"no\")):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        train_files[0].append(os.path.join(image_dir, \"no\", file))\n",
    "\n",
    "for file in os.listdir(os.path.join(image_dir, \"yes\")):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        train_files[1].append(os.path.join(image_dir, \"yes\", file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(2):\n",
    "    for file in train_files[i]:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "        img = cv2.Canny(img, 0, 255)\n",
    "        \n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        all_images.append(img)\n",
    "        \n",
    "        label = [0, 0]\n",
    "        label[i] = 1\n",
    "        all_labels.append(label)\n",
    "\n",
    "all_images = np.array(all_images)[..., np.newaxis]\n",
    "all_labels = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518, 21, 21, 1) (518, 2)\n",
      "1.0\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_images.shape, all_labels.shape)\n",
    "print(all_images.max())\n",
    "print(all_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14bf3e908>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(all_images[0][:, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "\n",
    "train_indices = random.sample(range(len(all_images)), int(len(all_images) * 0.8))\n",
    "\n",
    "for i in range(len(all_images)):\n",
    "    if i in train_indices:\n",
    "        train_images.append(all_images[i])\n",
    "        train_labels.append(all_labels[i])\n",
    "    else:\n",
    "        valid_images.append(all_images[i])\n",
    "        valid_labels.append(all_labels[i])\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "valid_images = np.array(valid_images)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=4,\n",
    "    height_shift_range=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(441, input_shape=(21, 21, 1)))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in [3, 2, 1]:\n",
    "        model.add(layers.Conv2D(16, j, activation=\"elu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "model.add(layers.Dense(128, activation=\"elu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "model.compile(optimizers.RMSprop(lr=1e-3), loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(train_images, train_labels, batch_size):\n",
    "    gen = datagen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "    while True:\n",
    "        x, y = gen.next()\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2136 - categorical_accuracy: 0.9203 - val_loss: 0.1934 - val_categorical_accuracy: 0.9423\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1783 - categorical_accuracy: 0.9251 - val_loss: 0.2098 - val_categorical_accuracy: 0.9423\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1722 - categorical_accuracy: 0.9396 - val_loss: 0.2076 - val_categorical_accuracy: 0.9519\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1771 - categorical_accuracy: 0.9396 - val_loss: 0.2976 - val_categorical_accuracy: 0.8846\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1976 - categorical_accuracy: 0.9251 - val_loss: 0.4123 - val_categorical_accuracy: 0.8269\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1751 - categorical_accuracy: 0.9372 - val_loss: 0.3107 - val_categorical_accuracy: 0.8942\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1750 - categorical_accuracy: 0.9348 - val_loss: 0.2645 - val_categorical_accuracy: 0.9135\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1625 - categorical_accuracy: 0.9372 - val_loss: 0.3356 - val_categorical_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1730 - categorical_accuracy: 0.9300 - val_loss: 0.3268 - val_categorical_accuracy: 0.8942\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2229 - categorical_accuracy: 0.9179 - val_loss: 0.3571 - val_categorical_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2103 - categorical_accuracy: 0.9130 - val_loss: 0.2431 - val_categorical_accuracy: 0.9135\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1902 - categorical_accuracy: 0.9348 - val_loss: 0.2137 - val_categorical_accuracy: 0.9423\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1858 - categorical_accuracy: 0.9372 - val_loss: 0.2487 - val_categorical_accuracy: 0.9135\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1816 - categorical_accuracy: 0.9324 - val_loss: 0.2014 - val_categorical_accuracy: 0.9231\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1683 - categorical_accuracy: 0.9203 - val_loss: 0.1997 - val_categorical_accuracy: 0.9231\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1921 - categorical_accuracy: 0.9324 - val_loss: 0.2257 - val_categorical_accuracy: 0.9135\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1649 - categorical_accuracy: 0.9275 - val_loss: 0.2006 - val_categorical_accuracy: 0.9327\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2037 - categorical_accuracy: 0.9251 - val_loss: 0.1967 - val_categorical_accuracy: 0.9423\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1879 - categorical_accuracy: 0.9444 - val_loss: 0.2142 - val_categorical_accuracy: 0.9327\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1742 - categorical_accuracy: 0.9493 - val_loss: 0.2093 - val_categorical_accuracy: 0.9327\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1672 - categorical_accuracy: 0.9275 - val_loss: 0.2390 - val_categorical_accuracy: 0.9038\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1831 - categorical_accuracy: 0.9420 - val_loss: 0.2465 - val_categorical_accuracy: 0.9231\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1747 - categorical_accuracy: 0.9300 - val_loss: 0.2006 - val_categorical_accuracy: 0.9327\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1589 - categorical_accuracy: 0.9469 - val_loss: 0.2063 - val_categorical_accuracy: 0.9135\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1849 - categorical_accuracy: 0.9300 - val_loss: 0.1857 - val_categorical_accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1672 - categorical_accuracy: 0.9396 - val_loss: 0.2187 - val_categorical_accuracy: 0.9231\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1654 - categorical_accuracy: 0.9444 - val_loss: 0.1855 - val_categorical_accuracy: 0.9423\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1827 - categorical_accuracy: 0.9348 - val_loss: 0.1627 - val_categorical_accuracy: 0.9423\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1626 - categorical_accuracy: 0.9348 - val_loss: 0.1543 - val_categorical_accuracy: 0.9519\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1935 - categorical_accuracy: 0.9324 - val_loss: 0.1504 - val_categorical_accuracy: 0.9423\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1775 - categorical_accuracy: 0.9372 - val_loss: 0.1530 - val_categorical_accuracy: 0.9327\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1804 - categorical_accuracy: 0.9275 - val_loss: 0.1688 - val_categorical_accuracy: 0.9327\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1928 - categorical_accuracy: 0.9300 - val_loss: 0.1949 - val_categorical_accuracy: 0.9327\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2125 - categorical_accuracy: 0.9155 - val_loss: 0.1821 - val_categorical_accuracy: 0.9231\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1704 - categorical_accuracy: 0.9348 - val_loss: 0.2065 - val_categorical_accuracy: 0.9135\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1794 - categorical_accuracy: 0.9372 - val_loss: 0.1932 - val_categorical_accuracy: 0.9423\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1927 - categorical_accuracy: 0.9372 - val_loss: 0.3922 - val_categorical_accuracy: 0.8462\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2111 - categorical_accuracy: 0.9155 - val_loss: 0.2155 - val_categorical_accuracy: 0.9135\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2083 - categorical_accuracy: 0.9203 - val_loss: 0.3977 - val_categorical_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1925 - categorical_accuracy: 0.9130 - val_loss: 0.3247 - val_categorical_accuracy: 0.8462\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2141 - categorical_accuracy: 0.9130 - val_loss: 0.1984 - val_categorical_accuracy: 0.9231\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2331 - categorical_accuracy: 0.9034 - val_loss: 0.3263 - val_categorical_accuracy: 0.8750\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1927 - categorical_accuracy: 0.9203 - val_loss: 0.2152 - val_categorical_accuracy: 0.9135\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2063 - categorical_accuracy: 0.9348 - val_loss: 0.2127 - val_categorical_accuracy: 0.9038\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1802 - categorical_accuracy: 0.9227 - val_loss: 0.2068 - val_categorical_accuracy: 0.9231\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1600 - categorical_accuracy: 0.9444 - val_loss: 0.3063 - val_categorical_accuracy: 0.8846\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1541 - categorical_accuracy: 0.9396 - val_loss: 0.1891 - val_categorical_accuracy: 0.9423\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1786 - categorical_accuracy: 0.9275 - val_loss: 0.2653 - val_categorical_accuracy: 0.9135\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1528 - categorical_accuracy: 0.9275 - val_loss: 0.2243 - val_categorical_accuracy: 0.9135\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1404 - categorical_accuracy: 0.9517 - val_loss: 0.4524 - val_categorical_accuracy: 0.8462\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1841 - categorical_accuracy: 0.9300 - val_loss: 0.1795 - val_categorical_accuracy: 0.9135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1959 - categorical_accuracy: 0.9348 - val_loss: 0.1840 - val_categorical_accuracy: 0.9231\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2145 - categorical_accuracy: 0.9251 - val_loss: 0.1776 - val_categorical_accuracy: 0.9231\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1947 - categorical_accuracy: 0.9227 - val_loss: 0.2234 - val_categorical_accuracy: 0.9231\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2022 - categorical_accuracy: 0.9300 - val_loss: 0.2678 - val_categorical_accuracy: 0.8942\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2032 - categorical_accuracy: 0.9275 - val_loss: 0.3125 - val_categorical_accuracy: 0.8654\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1661 - categorical_accuracy: 0.9444 - val_loss: 0.2509 - val_categorical_accuracy: 0.9038\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1844 - categorical_accuracy: 0.9203 - val_loss: 0.2857 - val_categorical_accuracy: 0.8846\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1711 - categorical_accuracy: 0.9396 - val_loss: 0.3126 - val_categorical_accuracy: 0.8654\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1698 - categorical_accuracy: 0.9324 - val_loss: 0.2600 - val_categorical_accuracy: 0.9038\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1758 - categorical_accuracy: 0.9469 - val_loss: 0.2700 - val_categorical_accuracy: 0.8846\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1792 - categorical_accuracy: 0.9444 - val_loss: 0.2712 - val_categorical_accuracy: 0.8750\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1786 - categorical_accuracy: 0.9275 - val_loss: 0.3943 - val_categorical_accuracy: 0.8269\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1992 - categorical_accuracy: 0.9300 - val_loss: 0.5131 - val_categorical_accuracy: 0.7981\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2228 - categorical_accuracy: 0.9179 - val_loss: 0.2730 - val_categorical_accuracy: 0.8846\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1723 - categorical_accuracy: 0.9300 - val_loss: 0.4318 - val_categorical_accuracy: 0.8558\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1690 - categorical_accuracy: 0.9396 - val_loss: 0.3755 - val_categorical_accuracy: 0.8269\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1702 - categorical_accuracy: 0.9203 - val_loss: 0.3336 - val_categorical_accuracy: 0.8846\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1800 - categorical_accuracy: 0.9420 - val_loss: 0.4381 - val_categorical_accuracy: 0.8558\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1773 - categorical_accuracy: 0.9251 - val_loss: 0.4783 - val_categorical_accuracy: 0.8365\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1756 - categorical_accuracy: 0.9324 - val_loss: 0.3948 - val_categorical_accuracy: 0.8462\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1684 - categorical_accuracy: 0.9420 - val_loss: 0.4214 - val_categorical_accuracy: 0.8654\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2369 - categorical_accuracy: 0.9179 - val_loss: 0.3323 - val_categorical_accuracy: 0.8462\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1836 - categorical_accuracy: 0.9227 - val_loss: 0.4227 - val_categorical_accuracy: 0.8462\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1971 - categorical_accuracy: 0.9396 - val_loss: 0.4941 - val_categorical_accuracy: 0.8077\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1778 - categorical_accuracy: 0.9300 - val_loss: 0.3099 - val_categorical_accuracy: 0.8654\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1794 - categorical_accuracy: 0.9275 - val_loss: 0.3021 - val_categorical_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1722 - categorical_accuracy: 0.9300 - val_loss: 0.3652 - val_categorical_accuracy: 0.8462\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1958 - categorical_accuracy: 0.9203 - val_loss: 0.1942 - val_categorical_accuracy: 0.9327\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1793 - categorical_accuracy: 0.9348 - val_loss: 0.2418 - val_categorical_accuracy: 0.9135\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1576 - categorical_accuracy: 0.9372 - val_loss: 0.3146 - val_categorical_accuracy: 0.8654\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2151 - categorical_accuracy: 0.9372 - val_loss: 0.2150 - val_categorical_accuracy: 0.9135\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1522 - categorical_accuracy: 0.9396 - val_loss: 0.2273 - val_categorical_accuracy: 0.9038\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1735 - categorical_accuracy: 0.9493 - val_loss: 0.2462 - val_categorical_accuracy: 0.8942\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1940 - categorical_accuracy: 0.9227 - val_loss: 0.2309 - val_categorical_accuracy: 0.9038\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1595 - categorical_accuracy: 0.9372 - val_loss: 0.1809 - val_categorical_accuracy: 0.9135\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1891 - categorical_accuracy: 0.9300 - val_loss: 0.1802 - val_categorical_accuracy: 0.9135\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1574 - categorical_accuracy: 0.9396 - val_loss: 0.1681 - val_categorical_accuracy: 0.9327\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1681 - categorical_accuracy: 0.9493 - val_loss: 0.1791 - val_categorical_accuracy: 0.9135\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1726 - categorical_accuracy: 0.9324 - val_loss: 0.1934 - val_categorical_accuracy: 0.9231\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1959 - categorical_accuracy: 0.9420 - val_loss: 0.2449 - val_categorical_accuracy: 0.9135\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1786 - categorical_accuracy: 0.9324 - val_loss: 0.1907 - val_categorical_accuracy: 0.9135\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2075 - categorical_accuracy: 0.9300 - val_loss: 0.1688 - val_categorical_accuracy: 0.9327\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1931 - categorical_accuracy: 0.9251 - val_loss: 0.1810 - val_categorical_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1439 - categorical_accuracy: 0.9396 - val_loss: 0.1926 - val_categorical_accuracy: 0.9423\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1912 - categorical_accuracy: 0.9300 - val_loss: 0.1603 - val_categorical_accuracy: 0.9519\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1552 - categorical_accuracy: 0.9324 - val_loss: 0.3192 - val_categorical_accuracy: 0.9135\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2074 - categorical_accuracy: 0.9251 - val_loss: 0.1885 - val_categorical_accuracy: 0.9135\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1728 - categorical_accuracy: 0.9372 - val_loss: 0.1804 - val_categorical_accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1680 - categorical_accuracy: 0.9469 - val_loss: 0.2021 - val_categorical_accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "batch_size = train_images.shape[0]\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit_generator(generate_data(train_images, train_labels, batch_size=batch_size),\n",
    "                              steps_per_epoch=train_images.shape[0] / batch_size,\n",
    "                              epochs=epochs, validation_data = (valid_images, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"lattice_points_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"lattice_points_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
